main-commands:
  title: "&8[&3ShadeAc&8] &bОсновные команды"
  lines:
    - "&3/shadeac help &8- &fПоказать это справочное сообщение."
    - "&3/sapunish <player> [reason] &8- &fЗапустить анимированное наказание для игрока."
    - "&3/sacml ... &8- &fКоманды для управления системой машинного обучения."

machine-learning-guide:
  title: "&8[&3ShadeAc&8] &bРуководство по Машинному Обучению"
  introduction:
    - "&fСистема машинного обучения (ML) в ShadeAc позволяет создать"
    - "&fуникальный детектор, обученный на поведении игроков вашего сервера."
    - "&fЭто делает его чрезвычайно точным и трудным для обхода."
    - "&fПроцесс состоит из 3 этапов: Сбор, Обучение, Применение."
    - "&fСобирайте много данных, модель будет фолсить на маленьких! и не нойте из-за этого в оценках!"

  step1-collection:
    title: "&bЭтап 1: Сбор данных (Команда: /sacml)"
    lines:
      - "&fВаша задача - собрать два набора данных: 'legit' (честная игра) и 'cheat' (игра с читами)."
      - "&fДля этого используйте команду:"
      - "  &3/sacml start <player> <legit|cheat> &8- &fНачать сбор данных."
      - "  &3/sacml stop <player> &8- &fОстановить сбор и сохранить файл."
      - "&e&lСоветы для качественного сбора:"
      - "&e- Собирайте данные в реальных боевых ситуациях (PvP)."
      - "&e- Для 'cheat' данных используйте разные типы килаур астаны клиенты подойдут."
      - "&e- Для 'legit' данных попросите нескольких разных игроков поиграть."
      - "&e- Чем больше данных (хотя бы по 5-10 минут каждого типа), тем лучше будет модель."
      - "&fВсе данные сохраняются в папку: &7plugins/ShadeAc/dataset/"

  step2-training:
    title: "&bЭтап 2: Обучение модели"
    lines:
      - "&fПосле того как вы собрали достаточно данных, запустите обучение:"
      - "  &3/sacml train [эпохи] &8- &fНачать обучение модели на собранных данных."
      - "&cИспользуйте ее только при низком онлайне или на тестовом сервере."
      - "&f'Эпохи' - это количество раз, которое нейросеть 'просмотрит' весь датасет."
      - "&fРекомендуемое значение для начала: &e100-200&f."
      - "&fПроцесс может занять от нескольких минут до часа в зависимости от объема данных."
      - "&fПосле завершения, обученная модель будет автоматически сохранена в &7network_weights.yml&f и загружена в античит."

  step3-usage:
    title: "&bЭтап 3: Применение и настройка"
    lines:
      - "&fПосле обучения ML-чек (&bKillaura HML&f) сразу начнет работать."
      - "&fВы можете настроить его в &7config.yml&f:"
      - "  &3threshold: 0.90 &8- &fПорог уверенности сети для флага (от 0.0 до 1.0)."
      - "&fЕсли вы получаете ложные флаги, попробуйте &eнемного повысить&f порог (например, до 0.95)."
      - "&fЕсли читы не детектятся, попробуйте &eнемного понизить&f порог (например, до 0.85) или собрать больше данных."
      - "&fВы можете повторять этапы 1 и 2 в любое время, чтобы дообучить и улучшить вашу модель."
      - "&fЕсли что-то не получается можно написать мне в тг @Fronzter для помощи."
